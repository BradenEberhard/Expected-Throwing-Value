{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tf_idf_functions import calculate_tfidf\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_test_sets(df, test_size=0.2, temporal_test_size=75, random_state=42):\n",
    "    \"\"\"\n",
    "    Splits the dataset into training, validation, temporal test, and thrower test sets.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): DataFrame containing throw data.\n",
    "    - test_size (float, optional): The proportion of the dataset to include in the validation set. Default is 0.2.\n",
    "    - temporal_test_size (int, optional): The number of games to include in the temporal test set. Default is 75.\n",
    "    - random_state (int, optional): Random seed for reproducibility. Default is 42.\n",
    "    \n",
    "    Returns:\n",
    "    - train_df (pd.DataFrame): Training set.\n",
    "    - val_df (pd.DataFrame): Validation set.\n",
    "    - temporal_test_df (pd.DataFrame): Temporal test set.\n",
    "    - thrower_test_df (pd.DataFrame): Hold-out test set for specific throwers.\n",
    "    \"\"\"\n",
    "    # Select 50 throwers with > 200 throws for hold-out-testing\n",
    "    throwers = df.groupby('thrower').thrower.count()\n",
    "    hold_out_throwers = np.array(throwers[throwers > 200].index)\n",
    "    np.random.seed(random_state)\n",
    "    hold_out_throwers = np.random.choice(hold_out_throwers, size=50, replace=False)\n",
    "    thrower_test_df = df[df.thrower.isin(hold_out_throwers)].copy()\n",
    "    df_filtered = df[~df.thrower.isin(hold_out_throwers)].copy()\n",
    "    \n",
    "    # Extract date and year\n",
    "    df_filtered.loc[:,'gameDate'] = pd.to_datetime(df_filtered.loc[:,'gameID'].str[:10], format='%Y-%m-%d')\n",
    "    df_filtered.loc[:,'year'] = df_filtered.loc[:,'gameDate'].dt.year\n",
    "    df_sorted = df_filtered.sort_values(by='gameDate')\n",
    "    \n",
    "    # Select 75 most recent games for hold-out-testing \n",
    "    unique_game_ids = df_sorted.loc[:,'gameID'].unique()\n",
    "    temporal_test_ids = unique_game_ids[-temporal_test_size:]\n",
    "    \n",
    "    # In remeaining data, split into test and train. Make sure the hold out testing set is balanced between years\n",
    "    remaining_ids = unique_game_ids[:-temporal_test_size]\n",
    "    total_remaining = len(remaining_ids)\n",
    "    num_games_per_year = int(total_remaining * test_size / 4)\n",
    "    remaining_df = df_sorted[df_sorted.loc[:,'gameID'].isin(remaining_ids)]\n",
    "    val_games = []\n",
    "    for year, group in remaining_df.groupby('year'):\n",
    "        sampled_games = group.sample(n=num_games_per_year, random_state=random_state)\n",
    "        val_games.append(sampled_games.loc[:,'gameID'].unique())\n",
    "    \n",
    "    val_ids = np.concatenate(val_games)\n",
    "    \n",
    "\n",
    "    train_ids = [game_id for game_id in remaining_ids if game_id not in val_ids]\n",
    "    train_df = df_filtered[df_filtered.loc[:,'gameID'].isin(train_ids)]\n",
    "    val_df = df_filtered[df_filtered.loc[:,'gameID'].isin(val_ids)]\n",
    "    temporal_test_df = df_filtered[df_filtered.loc[:,'gameID'].isin(temporal_test_ids)]\n",
    "    \n",
    "    return train_df, val_df, temporal_test_df, thrower_test_df\n",
    "\n",
    "\n",
    "def calculate_throw_direction_percentages(df):\n",
    "    \"\"\"\n",
    "    Calculates the percentage of throws categorized as forward, sideways, or backward for each thrower.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): DataFrame containing throw data, with 'thrower' and 'throw_distance' columns.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: Original DataFrame with new columns for throw direction percentages \n",
    "                    ('backward_percentage', 'sideways_percentage', 'forward_percentage').\n",
    "    \"\"\"\n",
    "\n",
    "    direction_counts = df.groupby(['thrower', 'direction_category']).size().unstack(fill_value=0)\n",
    "    direction_counts['total_throws'] = direction_counts.sum(axis=1)\n",
    "    direction_percentages = direction_counts.div(direction_counts['total_throws'], axis=0) * 100\n",
    "\n",
    "\n",
    "    direction_percentages = direction_percentages.rename(columns={\n",
    "        'Backwards': 'backward_percentage',\n",
    "        'Sideways': 'sideways_percentage',\n",
    "        'Forward': 'forward_percentage'\n",
    "    })\n",
    "    direction_percentages = direction_percentages.reset_index()\n",
    "    df = df.merge(direction_percentages[['thrower', 'backward_percentage', 'sideways_percentage', 'forward_percentage']],\n",
    "                   on='thrower', how='left')\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_data(filepath='./data/processed/all_games_0926.csv'):\n",
    "    \"\"\"\n",
    "    Initializes the dataset by loading a CSV file, processing the data to calculate various columns\n",
    "    like goal, outcome, point_outcome, throw_distance, and completion. The function handles missing values\n",
    "    and adjusts the 'times' column based on certain time limits.\n",
    "    \n",
    "    Parameters:\n",
    "    - filepath (str): The path to the CSV file containing the game data.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: The processed DataFrame with calculated columns.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    df = df.dropna(subset=['thrower_x', 'thrower_y'])\n",
    "    df.loc[:,'goal'] = (df.loc[:,'receiver_y'] > 100) & (df.loc[:,'turnover'] == 0)\n",
    "    df.loc[:,'outcome'] = 0  # 0 if possession ended without a goal otherwise 1\n",
    "    df.loc[:,'point_outcome'] = 0 # 0 if point ended without a goal otherwise 1\n",
    "    df.loc[:,'throw_distance'] = np.sqrt((df.loc[:,'receiver_x'] - df.loc[:,'thrower_x'])**2 + (df.loc[:,'receiver_y'] - df.loc[:,'thrower_y'])**2)\n",
    "    df.loc[:,'completion'] = 1 - df.loc[:,'turnover']\n",
    "    df.loc[:,'gameDate'] = pd.to_datetime(df.loc[:,'gameID'].str[:10], format='%Y-%m-%d')\n",
    "    df.loc[:,'year'] = df.loc[:,'gameDate'].dt.year\n",
    "\n",
    "\n",
    "    df['prev_receiver'] = df['receiver'].shift(1)\n",
    "    df['prev_thrower'] = df['thrower'].shift(1)\n",
    "    hockey_assists_df = df[\n",
    "        (df['receiver_y'] > 100) & (df['turnover'] == 0) & \n",
    "        (df['thrower'] == df['prev_receiver'])\n",
    "    ]\n",
    "\n",
    "    df['hockey_assist'] = 0  \n",
    "    df.loc[hockey_assists_df.index - 1, 'hockey_assist'] = 1  \n",
    "    df.drop(['prev_receiver', 'prev_thrower'], axis=1, inplace=True)\n",
    "\n",
    "    df.times = (df.times / 60)\n",
    "    df.loc[df['times'] < 0, 'times'] = df.loc[df['times'] < 0, 'times'] + 5\n",
    "    while len(df.times[df.times > 12]) > 0:\n",
    "        df.loc[df['times'] > 12, 'times'] = df.loc[df['times'] > 12, 'times'] - 12\n",
    "\n",
    "    for _, group in df.groupby(['gameID', 'home_team_score', 'away_team_score', 'possession_num', 'game_quarter']):\n",
    "        last_throw = group.iloc[-1]  \n",
    "        if last_throw['receiver_y'] > 100 and last_throw['turnover'] == 0:\n",
    "            df.loc[group.index, 'outcome'] = 1  \n",
    "    for _, group in df.groupby(['gameID', 'home_team_score', 'away_team_score', 'game_quarter']):\n",
    "        last_throw = group.iloc[-1]  # Get the last row in the group\n",
    "        if last_throw['receiver_y'] > 100 and last_throw['turnover'] == 0:\n",
    "            mask = group['is_home_team'] == last_throw['is_home_team']\n",
    "            df.loc[group[mask].index, 'point_outcome'] = 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_percentage(df, test_dfs=None):\n",
    "    \"\"\"\n",
    "    Calculate the completion percentage for each thrower and add it to the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): DataFrame containing throw data with a 'thrower' and 'completion' column.\n",
    "    - test_dfs (list of pd.DataFrame, optional): List of test DataFrames to which the completion percentage will also be added.\n",
    "    \n",
    "    Returns:\n",
    "    - train_df (pd.DataFrame): DataFrame with completion percentage added.\n",
    "    - test_dfs_final (list of pd.DataFrame): List of test DataFrames with completion percentage added (if provided).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Group by 'thrower' and calculate successful completions and total throws\n",
    "    completion_stats = df.groupby('thrower').agg(\n",
    "        successful_completions=('completion', 'sum'),  # Total successful completions per thrower\n",
    "        total_throws=('completion', 'count')  # Total number of throws per thrower\n",
    "    ).reset_index()\n",
    "\n",
    "    #  Calculate completion percentage for each thrower\n",
    "    completion_stats['completion_percentage'] = (\n",
    "        completion_stats['successful_completions'] / completion_stats['total_throws']\n",
    "    ) * 100\n",
    "    new_rows = completion_stats[['thrower', 'completion_percentage']].rename(\n",
    "        columns={'completion_percentage': 'thrower_completion_percentage'}\n",
    "    )\n",
    "    train_df = df.merge(new_rows, on='thrower', how='left').sort_values('thrower_completion_percentage')\n",
    "\n",
    "    test_dfs_final = []\n",
    "    if test_dfs is not None:\n",
    "        # For each test DataFrame, merge completion percentage and fill missing values with the median\n",
    "        for test_df in test_dfs:\n",
    "            test_df = test_df.merge(new_rows, on='thrower', how='left').sort_values('thrower_completion_percentage')\n",
    "            test_df.thrower_completion_percentage = test_df.thrower_completion_percentage.fillna(\n",
    "                test_df.thrower_completion_percentage.median()\n",
    "            )\n",
    "            test_dfs_final.append(test_df)\n",
    "\n",
    "    return train_df, test_dfs_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_categories(dfs):\n",
    "    \"\"\"\n",
    "    One-hot encode the 'distance_category' and 'direction_category' columns for each DataFrame in a list.\n",
    "    \n",
    "    Parameters:\n",
    "    - dfs (list of pd.DataFrame): List of DataFrames containing 'distance_category' and 'direction_category' columns.\n",
    "    \n",
    "    Returns:\n",
    "    - dfs_final (list of pd.DataFrame): List of DataFrames with new one-hot encoded columns for each unique category in 'distance_category' and 'direction_category'.\n",
    "    \"\"\"\n",
    "    \n",
    "    dfs_final = [] \n",
    "    \n",
    "    for df in dfs: \n",
    "        for category in df['distance_category'].unique():\n",
    "            df[f'distance_{category}'] = df['distance_category'] == category\n",
    "        for category in df['direction_category'].unique():\n",
    "            df[f'direction_{category}'] = df['direction_category'] == category\n",
    "        \n",
    "        dfs_final.append(df)\n",
    "    \n",
    "    return dfs_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_throw_direction_percentages(df, test_dfs=None):\n",
    "    \"\"\"\n",
    "    Calculate the percentage of throws in each direction (backward, sideways, forward) for each thrower.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): DataFrame containing throw data with 'thrower' and 'direction_category' columns.\n",
    "    - test_dfs (list of pd.DataFrames, optional): A list of DataFrames to apply the same percentage calculations to.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Original DataFrame with added columns for backward, sideways, and forward throw percentages.\n",
    "    - list of pd.DataFrames: (if test_dfs provided) List of test DataFrames with added percentage columns.\n",
    "    \"\"\"\n",
    "\n",
    "    direction_counts = df.groupby(['thrower', 'direction_category']).size().unstack(fill_value=0)\n",
    "    direction_counts['total_throws'] = direction_counts.sum(axis=1)\n",
    "\n",
    "    # Convert the counts to percentages by dividing by the total throws and multiply by 100\n",
    "    direction_counts['backward_percentage'] = (direction_counts['backward'] / direction_counts['total_throws']) * 100\n",
    "    direction_counts['sideways_percentage'] = (direction_counts['sideways'] / direction_counts['total_throws']) * 100\n",
    "    direction_counts['forward_percentage'] = (direction_counts['forward'] / direction_counts['total_throws']) * 100\n",
    "\n",
    "    direction_counts = direction_counts.reset_index()\n",
    "    df = df.merge(direction_counts[['thrower', 'backward_percentage', 'sideways_percentage', 'forward_percentage']],\n",
    "                  on='thrower', how='left')\n",
    "\n",
    "    # If test_dfs are provided, apply the same process to each test DataFrame\n",
    "    test_dfs_final = []\n",
    "    if test_dfs is not None:\n",
    "        for test_df in test_dfs:\n",
    "            test_df = test_df.merge(direction_counts[['thrower', 'backward_percentage', 'sideways_percentage', 'forward_percentage']],\n",
    "                                    on='thrower', how='left')\n",
    "            test_dfs_final.append(test_df)\n",
    "    \n",
    "    return df, test_dfs_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/processed/data_splits_1003.jblb']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath='../data/all_games_0926.csv'\n",
    "df = initialize_data(filepath)\n",
    "\n",
    "train_df, test_df_random, test_df_time, test_df_thrower = split_test_sets(df, random_state=0, test_size=0.4)\n",
    "train_df, test_dfs = get_completion_percentage(df, test_dfs=[test_df_random, test_df_time, test_df_thrower])\n",
    "train_df, test_dfs = calculate_tfidf(train_df, test_dfs)\n",
    "train_df, test_dfs = calculate_throw_direction_percentages(train_df, test_dfs)\n",
    "train_df, test_df_random, test_df_time, test_df_thrower = one_hot_encode_categories([train_df] + test_dfs)\n",
    "joblib.dump({'train_df':train_df, 'test_df_random':test_df_random, 'test_df_time':test_df_time, 'test_df_thrower':test_df_thrower}, '../data/processed/data_splits_1003.jblb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/processed/data_1003.jblb']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath='../data/all_games_0926.csv'\n",
    "df = initialize_data(filepath)\n",
    "df, _ = get_completion_percentage(df)\n",
    "df, _ = calculate_tfidf(df)\n",
    "df, _ = calculate_throw_direction_percentages(df)\n",
    "df = one_hot_encode_categories([df])[0]\n",
    "\n",
    "joblib.dump({'df':df}, '../data/processed/data_1003.jblb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
