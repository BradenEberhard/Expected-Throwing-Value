{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_test_sets(df, test_size=0.2, temporal_test_size=75, random_state=42):\n",
    "    \"\"\"\n",
    "    Splits the dataset into training, validation, temporal test, and thrower test sets.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): DataFrame containing throw data.\n",
    "    - test_size (float, optional): The proportion of the dataset to include in the validation set. Default is 0.2.\n",
    "    - temporal_test_size (int, optional): The number of games to include in the temporal test set. Default is 75.\n",
    "    - random_state (int, optional): Random seed for reproducibility. Default is 42.\n",
    "    \n",
    "    Returns:\n",
    "    - train_df (pd.DataFrame): Training set.\n",
    "    - val_df (pd.DataFrame): Validation set.\n",
    "    - temporal_test_df (pd.DataFrame): Temporal test set.\n",
    "    - thrower_test_df (pd.DataFrame): Hold-out test set for specific throwers.\n",
    "    \"\"\"\n",
    "    # Select 50 throwers with > 200 throws for hold-out-testing\n",
    "    throwers = df.groupby('thrower').thrower.count()\n",
    "    hold_out_throwers = np.array(throwers[throwers > 200].index)\n",
    "    np.random.seed(random_state)\n",
    "    hold_out_throwers = np.random.choice(hold_out_throwers, size=50, replace=False)\n",
    "    thrower_test_df = df[df.thrower.isin(hold_out_throwers)].copy()\n",
    "    df_filtered = df[~df.thrower.isin(hold_out_throwers)].copy()\n",
    "    \n",
    "    # Extract date and year\n",
    "    df_filtered.loc[:,'gameDate'] = pd.to_datetime(df_filtered.loc[:,'gameID'].str[:10], format='%Y-%m-%d')\n",
    "    df_filtered.loc[:,'year'] = df_filtered.loc[:,'gameDate'].dt.year\n",
    "    df_sorted = df_filtered.sort_values(by='gameDate')\n",
    "    \n",
    "    # Select 75 most recent games for hold-out-testing \n",
    "    unique_game_ids = df_sorted.loc[:,'gameID'].unique()\n",
    "    temporal_test_ids = unique_game_ids[-temporal_test_size:]\n",
    "    \n",
    "    # In remeaining data, split into test and train. Make sure the hold out testing set is balanced between years\n",
    "    remaining_ids = unique_game_ids[:-temporal_test_size]\n",
    "    total_remaining = len(remaining_ids)\n",
    "    num_games_per_year = int(total_remaining * test_size / 4)\n",
    "    remaining_df = df_sorted[df_sorted.loc[:,'gameID'].isin(remaining_ids)]\n",
    "    val_games = []\n",
    "    for year, group in remaining_df.groupby('year'):\n",
    "        sampled_games = group.sample(n=num_games_per_year, random_state=random_state)\n",
    "        val_games.append(sampled_games.loc[:,'gameID'].unique())\n",
    "    \n",
    "    val_ids = np.concatenate(val_games)\n",
    "    \n",
    "    # create final dfs\n",
    "    train_ids = [game_id for game_id in remaining_ids if game_id not in val_ids]\n",
    "    train_df = df_filtered[df_filtered.loc[:,'gameID'].isin(train_ids)]\n",
    "    val_df = df_filtered[df_filtered.loc[:,'gameID'].isin(val_ids)]\n",
    "    temporal_test_df = df_filtered[df_filtered.loc[:,'gameID'].isin(temporal_test_ids)]\n",
    "    \n",
    "    return train_df, val_df, temporal_test_df, thrower_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_data(filepath='./data/processed/all_games_0926.csv'):\n",
    "    \"\"\"\n",
    "    Initializes the dataset by loading a CSV file, processing the data to calculate various columns\n",
    "    like goal, outcome, point_outcome, throw_distance, and completion. The function handles missing values\n",
    "    and adjusts the 'times' column based on certain time limits.\n",
    "    \n",
    "    Parameters:\n",
    "    - filepath (str): The path to the CSV file containing the game data.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: The processed DataFrame with calculated columns.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    df = df.dropna(subset=['thrower_x', 'thrower_y'])\n",
    "    df.loc[:,'goal'] = (df.loc[:,'receiver_y'] > 100) & (df.loc[:,'turnover'] == 0)\n",
    "    df.loc[:,'outcome'] = 0  # 0 if possession ended without a goal otherwise 1\n",
    "    df.loc[:,'point_outcome'] = 0 # 0 if point ended without a goal otherwise 1\n",
    "    df.loc[:,'throw_distance'] = np.sqrt((df.loc[:,'receiver_x'] - df.loc[:,'thrower_x'])**2 + (df.loc[:,'receiver_y'] - df.loc[:,'thrower_y'])**2)\n",
    "    df['x_diff'] = df['receiver_x'] - df['thrower_x']\n",
    "    df['y_diff'] = df['receiver_y'] - df['thrower_y']\n",
    "    df['throw_angle'] = np.degrees(np.arctan2(df['y_diff'], df['x_diff']))\n",
    "    df.loc[:,'completion'] = 1 - df.loc[:,'turnover']\n",
    "    df.loc[:,'gameDate'] = pd.to_datetime(df.loc[:,'gameID'].str[:10], format='%Y-%m-%d')\n",
    "    df.loc[:,'year'] = df.loc[:,'gameDate'].dt.year\n",
    "    df = df.sort_values(['gameID', 'game_quarter', 'times'], ascending=[True, True, False])\n",
    "    df['quarter_point'] = ((df['home_team_score'] != df['home_team_score'].shift()) | (df['away_team_score'] != df['away_team_score'].shift()) | (df['gameID'] != df['gameID'].shift()) | (df['game_quarter'] != df['game_quarter'].shift())).groupby([df['gameID'], df['game_quarter']]).cumsum()\n",
    "\n",
    "\n",
    "    # get hockey assist by checking if previous receiver is the same as assist thrower\n",
    "    df['prev_receiver'] = df['receiver'].shift(1)\n",
    "    df['prev_thrower'] = df['thrower'].shift(1)\n",
    "    hockey_assists_df = df[\n",
    "        (df['receiver_y'] > 100) & (df['turnover'] == 0) & \n",
    "        (df['thrower'] == df['prev_receiver'])\n",
    "    ]\n",
    "\n",
    "    df['hockey_assist'] = 0  \n",
    "    df.loc[hockey_assists_df.index - 1, 'hockey_assist'] = 1  \n",
    "    df.drop(['prev_receiver', 'prev_thrower'], axis=1, inplace=True)\n",
    "\n",
    "    # convert times to minutes and show time left in quarter\n",
    "    df.times = (df.times / 60)\n",
    "    df.loc[df['times'] < 0, 'times'] = df.loc[df['times'] < 0, 'times'] + 5\n",
    "    while len(df.times[df.times > 12]) > 0:\n",
    "        df.loc[df['times'] > 12, 'times'] = df.loc[df['times'] > 12, 'times'] - 12\n",
    "    # there are no times for double OT so make it a full quarter time throughout\n",
    "    df.loc[df['game_quarter'] == 6, 'times'] = 12\n",
    "\n",
    "    # define outcome and point outcome\n",
    "    for _, group in df.groupby(['gameID', 'home_team_score', 'away_team_score', 'possession_num', 'game_quarter']):\n",
    "        last_throw = group.iloc[-1]  \n",
    "        if last_throw['receiver_y'] > 100 and last_throw['turnover'] == 0:\n",
    "            df.loc[group.index, 'outcome'] = 1  \n",
    "    for _, group in df.groupby(['gameID', 'home_team_score', 'away_team_score', 'game_quarter']):\n",
    "        last_throw = group.iloc[-1]  # Get the last row in the group\n",
    "        if last_throw['receiver_y'] > 100 and last_throw['turnover'] == 0:\n",
    "            mask = group['is_home_team'] == last_throw['is_home_team']\n",
    "            df.loc[group[mask].index, 'point_outcome'] = 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_percentage(df, test_dfs=None):\n",
    "    \"\"\"\n",
    "    Calculate the completion percentage for each thrower and add it to the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): DataFrame containing throw data with a 'thrower' and 'completion' column.\n",
    "    - test_dfs (list of pd.DataFrame, optional): List of test DataFrames to which the completion percentage will also be added.\n",
    "    \n",
    "    Returns:\n",
    "    - train_df (pd.DataFrame): DataFrame with completion percentage added.\n",
    "    - test_dfs_final (list of pd.DataFrame): List of test DataFrames with completion percentage added (if provided).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Group by 'thrower' and calculate successful completions and total throws\n",
    "    completion_stats = df.groupby('thrower').agg(\n",
    "        successful_completions=('completion', 'sum'),  # Total successful completions per thrower\n",
    "        total_throws=('completion', 'count')  # Total number of throws per thrower\n",
    "    ).reset_index()\n",
    "\n",
    "    #  Calculate completion percentage for each thrower\n",
    "    completion_stats['completion_percentage'] = (\n",
    "        completion_stats['successful_completions'] / completion_stats['total_throws']\n",
    "    ) * 100\n",
    "    new_rows = completion_stats[['thrower', 'completion_percentage']].rename(\n",
    "        columns={'completion_percentage': 'thrower_completion_percentage'}\n",
    "    )\n",
    "    train_df = df.merge(new_rows, on='thrower', how='left').sort_values('thrower_completion_percentage')\n",
    "\n",
    "    test_dfs_final = []\n",
    "    if test_dfs is not None:\n",
    "        # For each test DataFrame, merge completion percentage and fill missing values with the median\n",
    "        for test_df in test_dfs:\n",
    "            test_df = test_df.merge(new_rows, on='thrower', how='left').sort_values('thrower_completion_percentage')\n",
    "            test_df.thrower_completion_percentage = test_df.thrower_completion_percentage.fillna(\n",
    "                test_df.thrower_completion_percentage.median()\n",
    "            )\n",
    "            test_dfs_final.append(test_df)\n",
    "\n",
    "    return train_df, test_dfs_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/processed/data_splits_1003.jblb']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## processing to create data splits and calculate player features from only train data\n",
    "## used for model training, showing generalizability and predictability\n",
    "filepath='../data/all_games_1024.csv'\n",
    "df = initialize_data(filepath)\n",
    "\n",
    "train_df, test_df_random, test_df_time, test_df_thrower = split_test_sets(df, random_state=0, test_size=0.4)\n",
    "train_df, test_dfs = get_completion_percentage(df, test_dfs=[test_df_random, test_df_time, test_df_thrower])\n",
    "joblib.dump({'train_df':train_df, 'test_df_random':test_df_random, 'test_df_time':test_df_time, 'test_df_thrower':test_df_thrower}, '../data/processed/data_splits_1003.jblb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/processed/data_1003.jblb']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## processing for all throws into a single dataframe\n",
    "## used for descriptive purposes, meta analytics and derived metrics\n",
    "\n",
    "filepath='../data/all_games_1024.csv'\n",
    "df = initialize_data(filepath)\n",
    "df, _ = get_completion_percentage(df)\n",
    "joblib.dump({'df':df}, '../data/processed/data_1003.jblb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
